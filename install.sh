#!/bin/bash

# Script de instalaciÃ³n completa para el proyecto de anÃ¡lisis EDA
# Empresa de Aceros Largos - DesafÃ­o CDO

echo "ğŸš€ INSTALACIÃ“N COMPLETA - ANÃLISIS EDA EMPRESA DE ACEROS"
echo "=" * 60

# Verificar si estamos en Cloud Shell
if [ -z "$CLOUD_SHELL" ]; then
    echo "âš ï¸  ADVERTENCIA: Este script estÃ¡ diseÃ±ado para Google Cloud Shell"
    echo "   Para mejor experiencia, abre Cloud Shell y ejecuta este script"
    echo "   Continuando con instalaciÃ³n local..."
    echo ""
fi

# Configurar variables de entorno
export PROJECT_ID=$(gcloud config get-value project 2>/dev/null || echo "your-project-id")
export DATASET_NAME="acero_analysis"
export TABLE_NAME="cdo_challenge"

echo "ğŸ“Š ConfiguraciÃ³n del proyecto:"
echo "   - Proyecto GCP: $PROJECT_ID"
echo "   - Dataset: $DATASET_NAME"
echo "   - Tabla: $TABLE_NAME"
echo ""

# Crear estructura de directorios
echo "ğŸ“ Creando estructura de directorios..."
mkdir -p data
mkdir -p dbt/{models/{staging,intermediate,marts},tests,seeds,snapshots,macros,analyses}
mkdir -p notebooks
mkdir -p src
mkdir -p docs
mkdir -p presentations
mkdir -p scripts
mkdir -p reports
mkdir -p .github/workflows

echo "âœ… Estructura de directorios creada"
echo ""

# Verificar si gcloud estÃ¡ disponible
if command -v gcloud &> /dev/null; then
    echo "ğŸ”§ Configurando Google Cloud..."
    
    # Habilitar APIs necesarias
    echo "   Habilitando APIs..."
    gcloud services enable bigquery.googleapis.com
    gcloud services enable storage.googleapis.com
    gcloud services enable dataflow.googleapis.com
    
    # Configurar autenticaciÃ³n
    echo "   Configurando autenticaciÃ³n..."
    gcloud auth application-default login --no-launch-browser
    
    # Crear dataset en BigQuery
    echo "   Creando dataset en BigQuery..."
    bq mk --dataset --description "Dataset para anÃ¡lisis de aceros largos" $PROJECT_ID:$DATASET_NAME 2>/dev/null || echo "Dataset ya existe"
    
    echo "âœ… Google Cloud configurado"
else
    echo "âš ï¸  gcloud no estÃ¡ disponible. Configura Google Cloud manualmente."
fi

echo ""

# Instalar dependencias Python
echo "ğŸ Instalando dependencias Python..."
pip install --upgrade pip
pip install -r requirements.txt

echo "âœ… Dependencias Python instaladas"
echo ""

# Instalar dbt
echo "ğŸ”§ Instalando dbt..."
pip install dbt-bigquery

if command -v dbt &> /dev/null; then
    echo "âœ… dbt instalado correctamente"
    dbt --version
else
    echo "âŒ Error instalando dbt"
fi

echo ""

# Configurar permisos de ejecuciÃ³n
echo "ğŸ” Configurando permisos de ejecuciÃ³n..."
chmod +x scripts/*.sh
chmod +x install.sh

echo "âœ… Permisos configurados"
echo ""

# Verificar instalaciÃ³n
echo "ğŸ” Verificando instalaciÃ³n..."
echo ""

echo "ğŸ“‹ RESUMEN DE INSTALACIÃ“N:"
echo "   âœ… Estructura de directorios creada"
echo "   âœ… Dependencias Python instaladas"
echo "   âœ… dbt instalado"
echo "   âœ… Scripts configurados"
echo ""

if command -v gcloud &> /dev/null; then
    echo "   âœ… Google Cloud configurado"
    echo "   âœ… BigQuery dataset creado"
else
    echo "   âš ï¸  Google Cloud requiere configuraciÃ³n manual"
fi

echo ""

# Mostrar prÃ³ximos pasos
echo "ğŸš€ PRÃ“XIMOS PASOS:"
echo ""

if command -v gcloud &> /dev/null; then
    echo "1. ğŸ”„ Cargar datos en BigQuery:"
    echo "   python scripts/load_data.py"
    echo ""
    echo "2. ğŸ“Š Ejecutar anÃ¡lisis EDA:"
    echo "   python scripts/eda_analysis.py"
    echo ""
    echo "3. ğŸ”§ Configurar y ejecutar dbt:"
    echo "   ./scripts/setup_dbt.sh"
    echo ""
else
    echo "1. ğŸ”§ Configurar Google Cloud y BigQuery manualmente"
    echo "2. ğŸ”„ Cargar datos en BigQuery"
    echo "3. ğŸ“Š Ejecutar anÃ¡lisis EDA"
    echo "4. ğŸ”§ Configurar y ejecutar dbt"
    echo ""
fi

echo "4. ğŸ“š Revisar notebooks en la carpeta notebooks/"
echo "5. ğŸ“Š Verificar resultados en BigQuery"
echo "6. ğŸ“‹ Crear presentaciÃ³n PowerPoint basada en el template"
echo ""

# Verificar si el usuario quiere continuar con la carga de datos
if command -v gcloud &> /dev/null; then
    read -p "Â¿Deseas continuar con la carga de datos en BigQuery? (y/N): " -n 1 -r
    echo ""
    
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        echo "ğŸš€ Iniciando carga de datos..."
        echo "âš ï¸  ADVERTENCIA: Este proceso puede tomar varias horas debido al tamaÃ±o del archivo (113.33 GB)"
        echo ""
        
        read -p "Â¿EstÃ¡s seguro de continuar? (y/N): " -n 1 -r
        echo ""
        
        if [[ $REPLY =~ ^[Yy]$ ]]; then
            echo "ğŸš€ Ejecutando script de carga de datos..."
            python scripts/load_data.py
        else
            echo "â¸ï¸  Carga de datos cancelada. Puedes ejecutarla mÃ¡s tarde con: python scripts/load_data.py"
        fi
    else
        echo "â¸ï¸  Carga de datos pospuesta. Puedes ejecutarla mÃ¡s tarde con: python scripts/load_data.py"
    fi
fi

echo ""
echo "ğŸ‰ INSTALACIÃ“N COMPLETADA EXITOSAMENTE!"
echo ""
echo "ğŸ“ Estructura del proyecto creada:"
echo "   - data/           # Datos y scripts de procesamiento"
echo "   - dbt/            # Proyecto dbt para transformaciones"
echo "   - notebooks/      # Jupyter notebooks para anÃ¡lisis EDA"
echo "   - src/            # CÃ³digo fuente Python"
echo "   - docs/           # DocumentaciÃ³n"
echo "   - presentations/  # Presentaciones PowerPoint"
echo "   - scripts/        # Scripts de automatizaciÃ³n"
echo "   - reports/        # Reportes de calidad"
echo ""
echo "ğŸ”— Recursos Ãºtiles:"
echo "   - README.md: DocumentaciÃ³n principal del proyecto"
echo "   - requirements.txt: Dependencias Python"
echo "   - scripts/: Scripts de configuraciÃ³n y ejecuciÃ³n"
echo "   - dbt/: Proyecto de transformaciones de datos"
echo ""
echo "ğŸ“ Para soporte o preguntas, revisa la documentaciÃ³n o contacta al equipo."
echo ""
echo "Â¡Buena suerte con tu anÃ¡lisis EDA! ğŸš€"
